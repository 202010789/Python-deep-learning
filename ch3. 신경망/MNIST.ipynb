{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 작업 디렉터리: /Users/yumingyun/Desktop/smu/밑시딥/Python-deep-learning\n",
      "Python 경로 목록: ['/usr/local/Caskroom/miniforge/base/envs/deep/lib/python39.zip', '/usr/local/Caskroom/miniforge/base/envs/deep/lib/python3.9', '/usr/local/Caskroom/miniforge/base/envs/deep/lib/python3.9/lib-dynload', '', '/usr/local/Caskroom/miniforge/base/envs/deep/lib/python3.9/site-packages', '..', '..', '..', '..', '/Users/yumingyun/Desktop/smu/밑시딥/Python-deep-learning', '/Users/yumingyun/Desktop/smu/밑시딥/Python-deep-learning', '/Users/yumingyun/Desktop/smu/밑시딥/Python-deep-learning', '..', '/Users/yumingyun/Desktop/smu/밑시딥/Python-deep-learning', '/Users/yumingyun/Desktop/smu/밑시딥', '..', '/usr/local/Caskroom/miniforge/base/envs/deep/lib/python3.9/site-packages/setuptools/_vendor', '..', '..', '..', '..', '/Users/yumingyun/Desktop/smu/밑시딥/dataset', '..', '..', '..', '..']\n",
      "✅ MNIST 모듈이 성공적으로 로드되었습니다!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# '밑시딥' 경로를 sys.path에 추가\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "# 확인\n",
    "print(\"현재 작업 디렉터리:\", os.getcwd())\n",
    "print(\"Python 경로 목록:\", sys.path)\n",
    "\n",
    "# MNIST 모듈 가져오기\n",
    "try:\n",
    "    from dataset.mnist import load_mnist\n",
    "    print(\"✅ MNIST 모듈이 성공적으로 로드되었습니다!\")\n",
    "except ModuleNotFoundError as e:\n",
    "    print(\"❌ 오류 발생:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from dataset.mnist import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist.pkl already exists. Skipping creation.\n",
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 1. mnist.py가 상위 폴더의 dataset 폴더 안에 있는 경우\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # 상위 디렉토리 경로\n",
    "dataset_dir = os.path.join(parent_dir, \"dataset\") # dataset 폴더 경로\n",
    "if dataset_dir not in sys.path:\n",
    "    sys.path.append(dataset_dir)\n",
    "try:\n",
    "    from mnist import load_mnist # dataset 폴더가 sys.path에 추가되었으므로 이렇게 import\n",
    "except ModuleNotFoundError:\n",
    "    print(\"mnist.py가 dataset 폴더에 있는지, dataset 폴더가 올바른 경로에 있는지 확인하세요.\")\n",
    "    sys.exit()\n",
    "try:\n",
    "    (x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\n",
    "except FileNotFoundError as e: # mnist.py에서 발생시킨 FileNotFoundError를 잡음\n",
    "    print(f\"오류: {e}\")\n",
    "    print(\"MNIST 데이터 파일(.gz 파일)들을 mnist.py와 같은 폴더에 넣어주세요.\") # 더 친절한 안내\n",
    "    sys.exit()\n",
    "except Exception as e: # 다른 예외 발생 시 처리\n",
    "    print(f\"데이터 로드 중 오류 발생: {e}\")\n",
    "    sys.exit()\n",
    "\n",
    "# 데이터 확인 (선택적)\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)\n",
    "print(x_test.shape)\n",
    "print(t_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "(784,)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def img_show(img):\n",
    "    pil_img = Image.fromarray(np.uint8(img))\n",
    "    pil_img.show()\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\n",
    "\n",
    "img = x_train[0]\n",
    "label = t_train[0]\n",
    "print(label)  # 5\n",
    "\n",
    "print(img.shape)  # (784,)\n",
    "img = img.reshape(28, 28)  # 형상을 원래 이미지의 크기로 변형\n",
    "print(img.shape)  # (28, 28)\n",
    "\n",
    "img_show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import pickle\n",
    "from dataset.mnist import load_mnist\n",
    "from common.functions import sigmoid, softmax\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)\n",
    "    return x_test, t_test\n",
    "\n",
    "\n",
    "def init_network():\n",
    "    with open(\"sample_weight.pkl\", 'rb') as f:\n",
    "        network = pickle.load(f)\n",
    "    return network\n",
    "\n",
    "\n",
    "def predict(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "\n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = softmax(a3)\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "x, t = get_data()\n",
    "network = init_network()\n",
    "accuracy_cnt = 0\n",
    "for i in range(len(x)):\n",
    "    y = predict(network, x[i])\n",
    "    p= np.argmax(y) # 확률이 가장 높은 원소의 인덱스를 얻는다.\n",
    "    if p == t[i]:\n",
    "        accuracy_cnt += 1\n",
    "\n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 \n",
    "import numpy as np\n",
    "import pickle\n",
    "from dataset.mnist import load_mnist\n",
    "from common.functions import sigmoid, softmax\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)\n",
    "    return x_test, t_test\n",
    "\n",
    "\n",
    "def init_network():\n",
    "    with open(\"sample_weight.pkl\", 'rb') as f:\n",
    "        network = pickle.load(f)\n",
    "    return network\n",
    "\n",
    "\n",
    "def predict(network, x):\n",
    "    w1, w2, w3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "\n",
    "    a1 = np.dot(x, w1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, w2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, w3) + b3\n",
    "    y = softmax(a3)\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "batch_size = 100 # 배치 크기\n",
    "accuracy_cnt = 0\n",
    "\n",
    "for i in range(0, len(x), batch_size):\n",
    "    x_batch = x[i:i+batch_size]\n",
    "    y_batch = predict(network, x_batch)\n",
    "    p = np.argmax(y_batch, axis=1)\n",
    "    accuracy_cnt += np.sum(p == t[i:i+batch_size])\n",
    "\n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
